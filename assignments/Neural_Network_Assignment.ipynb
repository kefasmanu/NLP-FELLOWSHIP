{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kefasmanu/NLP-FELLOWSHIP/blob/main/assignments/Neural_Network_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6acSYAKEGxTa"
      },
      "source": [
        "# First Model Assignment\n",
        "The aim of this assignment is to make sure you understand the foundations of model training. We have covered traditional ML and also simple NN. You task is \n",
        "1. to write code for training traditional ML model that gives the highest accuracy\n",
        "2. Code for NN model that gives the highest accuracy\n",
        "\n",
        "## This we will consider\n",
        "1. The code works\n",
        "2. The hyperparameter used for fine tuning - epoch only is not enough\n",
        "3. The highest accuracy\n",
        "4. Bonus points for being creative with preprocessing, tokenization and creation of vectors\n",
        "\n",
        "# Submissions\n",
        "1. Notebook with code\n",
        "2. 2 models\n",
        "\n",
        "# Deadline\n",
        "Monday 28th at 5pm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NEURAL NETWORK**"
      ],
      "metadata": {
        "id": "xSHhSJ_pd1Ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTING DRIVE TO COLAB"
      ],
      "metadata": {
        "id": "l0C-m7-PUsGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igh17CfkUs4K",
        "outputId": "22c25e71-2121-41a7-fb06-80fa46dcba8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/MyDrive/NLP FELLOWSHIP/week 6/day 2\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvEkjO1LVEWZ",
        "outputId": "1696e096-329d-43b1-c82b-7f9cf9bd1cc6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50k_imdb_movie_reviews.csv  NLPNN.ipynb  saved_weights_linear.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Data"
      ],
      "metadata": {
        "id": "6SXjF89GiDrB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7O0sho4Tcf00",
        "outputId": "89415ed9-3937-4c30-8704-e23dd7010947"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment   set\n",
              "0  I went and saw this movie last night after bei...          1  test\n",
              "1  Actor turned director Bill Paxton follows up h...          1  test\n",
              "2  As a recreational golfer with some knowledge o...          1  test\n",
              "3  I saw this film in a sneak preview, and it is ...          1  test\n",
              "4  Bill Paxton has taken the true story of the 19...          1  test"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb5ddf36-aa22-4068-8acb-4ef71a079afb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb5ddf36-aa22-4068-8acb-4ef71a079afb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb5ddf36-aa22-4068-8acb-4ef71a079afb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb5ddf36-aa22-4068-8acb-4ef71a079afb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "full_dataset = pd.read_csv('50k_imdb_movie_reviews.csv')\n",
        "full_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECKING TO SEE IF THE  CLASSES (0,1) IN THE DATA SET IS BALANCED"
      ],
      "metadata": {
        "id": "2kLjoRz2i_t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No of positive in train : \"+str(len(full_dataset[(full_dataset['sentiment'] == 1) & (full_dataset['set'] == 'train')])))\n",
        "print(\"No of negative in train : \"+str(len(full_dataset[(full_dataset['sentiment'] == 0) & (full_dataset['set'] == 'train')])))\n",
        "print(\"No of positive in test : \"+str(len(full_dataset[(full_dataset['sentiment'] == 1) & (full_dataset['set'] == 'test')])))\n",
        "print(\"No of negative in test : \"+str(len(full_dataset[(full_dataset['sentiment'] == 0) & (full_dataset['set'] == 'test')])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPgcoYKxh8Gx",
        "outputId": "0ccb4814-0ed5-4db7-8741-208aca65f47f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of positive in train : 12500\n",
            "No of negative in train : 12500\n",
            "No of positive in test : 12500\n",
            "No of negative in test : 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECKING FOR DUPLICATES AND IF ANY DROP"
      ],
      "metadata": {
        "id": "MdGl9_Yuvqbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset['review'].describe()\n"
      ],
      "metadata": {
        "id": "6nqK4xQLtnvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2493e20-9a94-4857-f01b-4e97ecfe17ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                                                 50000\n",
              "unique                                                49582\n",
              "top       Loved today's show!!! It was a variety and not...\n",
              "freq                                                      5\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping duplicates\n",
        "full_dataset = full_dataset.drop_duplicates(subset=['review'])\n",
        "#Results Review after duplicates removal\n",
        "full_dataset['review'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF04EfJxXzVb",
        "outputId": "4b0c0625-72bc-42a1-a739-0272ce7e0344"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                                                 49582\n",
              "unique                                                49582\n",
              "top       I went and saw this movie last night after bei...\n",
              "freq                                                      1\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIRMING THE BALANCENESS OF THE TARGET CLASS(0,1) AFTER DROPPING DUPLICATES "
      ],
      "metadata": {
        "id": "RK-yvqwWwl2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No of positive in train : \"+str(len(full_dataset[(full_dataset['sentiment'] == 1) & (full_dataset['set'] == 'train')])))\n",
        "print(\"No of negative in train : \"+str(len(full_dataset[(full_dataset['sentiment'] == 0) & (full_dataset['set'] == 'train')])))\n",
        "print(\"No of positive in test : \"+str(len(full_dataset[(full_dataset['sentiment'] == 1) & (full_dataset['set'] == 'test')])))\n",
        "print(\"No of negative in test : \"+str(len(full_dataset[(full_dataset['sentiment'] == 0) & (full_dataset['set'] == 'test')])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2-U2TP-vvwb",
        "outputId": "fe16ab7c-8f0e-40b3-fd12-7551934f6850"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of positive in train : 12444\n",
            "No of negative in train : 12337\n",
            "No of positive in test : 12440\n",
            "No of negative in test : 12361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jKK3uU7YYSk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN AND TEST SETS SPLITS"
      ],
      "metadata": {
        "id": "MddbU1uUxZK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = full_dataset[(full_dataset['set'] == 'train')][['review','sentiment']]\n",
        "test_dataset = full_dataset[(full_dataset['set'] == 'test')][['review','sentiment']]\n",
        "test_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TIo-cis_w-hm",
        "outputId": "b80916d8-d1f1-472f-83ac-8b998216e98d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  I went and saw this movie last night after bei...          1\n",
              "1  Actor turned director Bill Paxton follows up h...          1\n",
              "2  As a recreational golfer with some knowledge o...          1\n",
              "3  I saw this film in a sneak preview, and it is ...          1\n",
              "4  Bill Paxton has taken the true story of the 19...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bb37d33-dd8d-4983-b60c-69c62ae6acc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb37d33-dd8d-4983-b60c-69c62ae6acc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bb37d33-dd8d-4983-b60c-69c62ae6acc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bb37d33-dd8d-4983-b60c-69c62ae6acc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION FOR DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "AvqfUw5VxqZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocessing(texts):\n",
        "  cleaned_text = []\n",
        "  for text in texts:\n",
        "    text = text.lower()\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                                u\"\\U00002702-\\U000027B0\"\n",
        "                                u\"\\U000024C2-\\U0001F251\"\n",
        "                                \"]+\", flags=re.UNICODE)\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    html_pattern = re.compile('<.*?>')\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    text = url_pattern.sub(r'', text)\n",
        "    text = html_pattern.sub(r'', text)\n",
        "    text = re.sub(r\"[^\\w\\d'\\s]+\", ' ', text)\n",
        "    cleaned_text.append(text)\n",
        "\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "tHno1_cUxlVX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0 torchtext==0.9.0 #compatibility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYnfmxhTx_rb",
        "outputId": "7e086758-17cd-40d9-82b4-33186dfb78ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 10 kB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 23.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset transformation to tensors Process"
      ],
      "metadata": {
        "id": "Bxuy3Apjy0Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy.data import Dataset, Example\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True # Check this\n",
        "max_document_length = 300 #hyperparameter\n",
        "\n",
        "TEXT = data.Field(lower=True, include_lengths=True,  tokenize='spacy',preprocessing=preprocessing,batch_first=True,  fix_length=max_document_length)\n",
        "LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51cZH6lWydCx",
        "outputId": "c5964db0-cd1d-42e1-eadd-904472010899"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Test dataset into tensors"
      ],
      "metadata": {
        "id": "ZGpTWqbG0G1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_valid_dataset, torch_test_dataset = DataFrameDataset(\n",
        "    df=test_dataset, \n",
        "    fields=(\n",
        "        ('review', TEXT),\n",
        "        ('sentiment', LABEL)\n",
        "    )\n",
        ").split()"
      ],
      "metadata": {
        "id": "dKOBdKOs7wvN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform Train dataset into tensors"
      ],
      "metadata": {
        "id": "tgUJrQ3M0hYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_train_dataset = DataFrameDataset(\n",
        "    df=train_dataset, \n",
        "    fields=(\n",
        "        ('review', TEXT),\n",
        "        ('sentiment', LABEL)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "Odf7BfUt7z1E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform text into numbers"
      ],
      "metadata": {
        "id": "rHnkP3xw2NhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_size = 30000 #hyperparameter\n",
        "TEXT.build_vocab(torch_train_dataset, max_size=max_size,vectors='fasttext.simple.300d')\n",
        "vocab_size = len(TEXT.vocab)"
      ],
      "metadata": {
        "id": "6bw-AGQx74Jg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "metadata": {
        "id": "Dr-nt8t777w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a557705a-bd7c-402a-e13a-16a3b6ab0321"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(' ', 785692), ('the', 326108), ('and', 161663), ('a', 160563), ('of', 144477), ('to', 134325), ('is', 109343), ('it', 92798), ('in', 92099), ('i', 81980), ('this', 72819), ('that', 72538), (\"'s\", 61640), (' br', 52238), ('was', 49935), ('as', 45797), ('for', 43582), ('with', 43503), ('movie', 42699), ('but', 41298)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch size creation for Both train and test set"
      ],
      "metadata": {
        "id": "T9ecnPpK3CeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 #hyperparameter\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (torch_train_dataset, torch_valid_dataset, torch_test_dataset), \n",
        "    batch_size = BATCH_SIZE ,\n",
        "    sort_key=lambda x: len(x.review),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "lecDcpcu7-9t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network model creation process"
      ],
      "metadata": {
        "id": "4C0V2p1A3SWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LR(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,hidden_size2, num_classes):\n",
        "        super(LR, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) # \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size2) \n",
        "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
        "\n",
        "    def forward(self, text):\n",
        "        text = text.float() # dense layer deals just with float type data\n",
        "        x = self.fc1(text) #(m x n) with (n x p)\n",
        "        x = self.relu(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        \n",
        "        preds = self.fc3(x) # crossentropyloss handles the softmax\n",
        "        # preds = F.softmax(preds,1) # nn.softmax\n",
        "        return preds"
      ],
      "metadata": {
        "id": "QdwPtVJX8BSO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper parameters Tuning and Neural Network Model implementation"
      ],
      "metadata": {
        "id": "vlwNfU7w3u7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "dropout_keep_prob = 0.5\n",
        "embedding_size = 300\n",
        "max_document_length = 300 # each sentence has until 100 words\n",
        "vocab_size = len(TEXT.vocab)\n",
        "dev_size = 0.8 # split percentage to train\\validation data\n",
        "max_size = 30000 # maximum vocabulary size\n",
        "seed = 42\n",
        "num_classes = 2\n",
        "\n",
        "num_epochs = 10\n",
        "hidden_size = 200\n",
        "hidden_size1 = 100\n",
        "hidden_size2 = 50\n",
        "hidden_size3 = 25\n",
        "\n",
        "to_train = True\n",
        "\n",
        "model = LR(max_document_length, hidden_size,hidden_size2, num_classes)"
      ],
      "metadata": {
        "id": "3rK21VXJ8EGb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Computation function"
      ],
      "metadata": {
        "id": "M3gqWARd4rdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(probs, target):\n",
        "  winners = probs.argmax(dim=1)\n",
        "  corrects = (winners == target)\n",
        "  accuracy = corrects.sum().float() / float(target.size(0))\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "az9Y_ipi8Ht7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model's backpropagation and fine Tuing"
      ],
      "metadata": {
        "id": "-BX2GfdK5J83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "  for batch in train_iterator:\n",
        "      optimizer.zero_grad()\n",
        "      # retrieve text and no. of words\n",
        "      text, text_lengths = batch.review\n",
        "\n",
        "      #feedforward\n",
        "      predictions = model(text).squeeze(1)\n",
        "      \n",
        "      \n",
        "      loss = loss_func(predictions, batch.sentiment)\n",
        "\n",
        "      acc = accuracy(predictions, batch.sentiment)\n",
        "\n",
        "      # perform backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      train_epoch_loss += loss.item()\n",
        "      train_epoch_acc += acc.item()\n",
        "\n",
        "  \n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch in valid_iterator:\n",
        "          text, text_lengths = batch.review\n",
        "\n",
        "          predictions = model(text).squeeze(1)\n",
        "\n",
        "          loss = loss_func(predictions, batch.sentiment)\n",
        "\n",
        "          acc = accuracy(predictions, batch.sentiment)\n",
        "\n",
        "          valid_epoch_loss += loss.item()\n",
        "          valid_epoch_acc += acc.item()\n",
        "\n",
        "   \n",
        "\n",
        "  if valid_epoch_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_epoch_loss\n",
        "            torch.save(model.state_dict(), 'saved_weights'+'_linear.pt')\n",
        "\n",
        "  print(f'\\tTrain Loss: {train_epoch_loss / len(train_iterator):.3f} | Train Acc: {train_epoch_acc  / len(train_iterator)* 100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_epoch_loss / len(valid_iterator):.3f} |  Val. Acc: {valid_epoch_acc / len(valid_iterator) * 100:.2f}%')"
      ],
      "metadata": {
        "id": "Hm91xMRd8J8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4c01c0-1987-49bd-88a7-eac27a95786f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 34.443 | Train Acc: 50.06%\n",
            "\t Val. Loss: 11.055 |  Val. Acc: 49.86%\n",
            "\tTrain Loss: 4.217 | Train Acc: 51.36%\n",
            "\t Val. Loss: 1.496 |  Val. Acc: 49.82%\n",
            "\tTrain Loss: 1.002 | Train Acc: 50.19%\n",
            "\t Val. Loss: 0.961 |  Val. Acc: 50.21%\n",
            "\tTrain Loss: 0.779 | Train Acc: 50.89%\n",
            "\t Val. Loss: 0.863 |  Val. Acc: 50.38%\n",
            "\tTrain Loss: 0.725 | Train Acc: 50.11%\n",
            "\t Val. Loss: 0.826 |  Val. Acc: 49.45%\n",
            "\tTrain Loss: 0.707 | Train Acc: 50.31%\n",
            "\t Val. Loss: 0.823 |  Val. Acc: 49.90%\n",
            "\tTrain Loss: 0.696 | Train Acc: 50.67%\n",
            "\t Val. Loss: 0.812 |  Val. Acc: 50.67%\n",
            "\tTrain Loss: 0.692 | Train Acc: 51.02%\n",
            "\t Val. Loss: 0.810 |  Val. Acc: 50.41%\n",
            "\tTrain Loss: 0.689 | Train Acc: 50.88%\n",
            "\t Val. Loss: 0.816 |  Val. Acc: 50.34%\n",
            "\tTrain Loss: 0.686 | Train Acc: 51.01%\n",
            "\t Val. Loss: 0.812 |  Val. Acc: 50.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL 2: Using Embedding Layer as Input to fine tune the result"
      ],
      "metadata": {
        "id": "YrPwuW24GIof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network function"
      ],
      "metadata": {
        "id": "uEyJ4b8XfcRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size2, hidden_size3, hidden_size4, output_dim, dropout, max_document_length):\n",
        "        super().__init__()\n",
        "        # embedding and convolution layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(embed_size*max_document_length, hidden_size2)  # dense layer\n",
        "        self.fc2 = nn.Linear(hidden_size2, hidden_size3)  # dense layer\n",
        "        self.fc3 = nn.Linear(hidden_size3, hidden_size4)  # dense layer\n",
        "        self.fc4 = nn.Linear(hidden_size4, output_dim)  # dense layer\n",
        "\n",
        "    def forward(self, text):\n",
        "         # text shape = (batch_size, num_sequences)\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        \n",
        "        x = embedded.view(embedded.shape[0], -1)  # x = Flatten()(x)\n",
        "        #embedded = embedded.unsqueeze(1) # fc gets 4 dimension\n",
        "        \n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        preds = self.fc4(x)\n",
        "        # preds = F.softmax(preds, 1)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "BrnRX77EGHVC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "h-Qm6T94gLPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-5\n",
        "batch_size = 64\n",
        "dropout_keep_prob = 0.5\n",
        "embedding_size = 300\n",
        "max_document_length = 300 # each sentence has until 100 words\n",
        "vocab_size = len(TEXT.vocab)\n",
        "dev_size = 0.8 # split percentage to train\\validation data\n",
        "max_size = 30000 # maximum vocabulary size\n",
        "seed = 42\n",
        "num_classes = 2\n",
        "\n",
        "num_epochs = 4\n",
        "hidden_size = 200\n",
        "hidden_size1 = 100\n",
        "hidden_size2 = 50\n",
        "hidden_size3 = 25\n",
        "\n",
        "to_train = True\n",
        "\n",
        "model = MLP(vocab_size, embedding_size, hidden_size1, hidden_size2, hidden_size3,  num_classes, dropout_keep_prob, max_document_length)"
      ],
      "metadata": {
        "id": "zz7arIL5gB7P"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Computation function"
      ],
      "metadata": {
        "id": "GbSWVv20jAM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(probs, target):\n",
        "  winners = probs.argmax(dim=1)\n",
        "  corrects = (winners == target)\n",
        "  accuracy = corrects.sum().float() / float(target.size(0))\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "vvs62Icein4O"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training through Forward and Backward"
      ],
      "metadata": {
        "id": "fFoLSnyRjO9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_epoch_loss = 0\n",
        "  train_epoch_acc = 0\n",
        "  for batch in train_iterator:\n",
        "      optimizer.zero_grad()\n",
        "      # retrieve text and no. of words\n",
        "      text, text_lengths = batch.review\n",
        "\n",
        "      #feedforward\n",
        "      predictions = model(text).squeeze(1)\n",
        "      \n",
        "      \n",
        "      loss = loss_func(predictions, batch.sentiment)\n",
        "\n",
        "      acc = accuracy(predictions, batch.sentiment)\n",
        "\n",
        "      # perform backpropagation\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      train_epoch_loss += loss.item()\n",
        "      train_epoch_acc += acc.item()\n",
        "\n",
        "  \n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for batch in valid_iterator:\n",
        "          text, text_lengths = batch.review\n",
        "\n",
        "          predictions = model(text).squeeze(1)\n",
        "\n",
        "          loss = loss_func(predictions, batch.sentiment)\n",
        "\n",
        "          acc = accuracy(predictions, batch.sentiment)\n",
        "\n",
        "          valid_epoch_loss += loss.item()\n",
        "          valid_epoch_acc += acc.item()\n",
        "\n",
        "   \n",
        "\n",
        "  if valid_epoch_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_epoch_loss\n",
        "            torch.save(model.state_dict(), 'saved_weights'+'_linear.pt')\n",
        "\n",
        "  print(f'\\tTrain Loss: {train_epoch_loss / len(train_iterator):.3f} | Train Acc: {train_epoch_acc  / len(train_iterator)* 100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_epoch_loss / len(valid_iterator):.3f} |  Val. Acc: {valid_epoch_acc / len(valid_iterator) * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qObc6OKsiuMg",
        "outputId": "2b62a300-d34b-49e9-bd5a-9679cba58696"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.696 | Train Acc: 50.78%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 51.37%\n",
            "\tTrain Loss: 0.687 | Train Acc: 57.07%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 54.55%\n",
            "\tTrain Loss: 0.657 | Train Acc: 65.80%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 54.86%\n",
            "\tTrain Loss: 0.575 | Train Acc: 73.98%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 60.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NyTCVAnBdjx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}